{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Santiment Hands On Blockchain Analytics Tutorial </center>\n",
    "# <center><b> Pumps&Dumps on Centralized Exchanges </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alexander Grablevski @Santiment.net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Santiment Hands On Tutorial!\n",
    "Next hour we will be speaking about:\n",
    "- How in Santiment we think about Ethereum data\n",
    "- What is the difference between Centralized and Decentralized exchanges\n",
    "- Pumps on centralized Exchanges\n",
    "- Conclusions and thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> How we think about Ethereum data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Challenges </b>\n",
    "- Dealing with LARGE amount of data\n",
    "- Crunching different blockchain types (UTXO and account-based)\n",
    "- Maintaining real-time systems\n",
    "- Providing fault-tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Engineering starts with quering blockchain fullnode and ends in the database with analyzable data format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to export the Data: https://github.com/santiment/eth-exporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about Ethereum data from transactions perspective (<b>transaction</b> = unit of data)\n",
    "\n",
    "<b>Transfer Transaction:</b>\n",
    "- Timestamp (datetime or blockNumber)\n",
    "- Sender\n",
    "- Receiver\n",
    "- Sended amount\n",
    "- Token (ETH, ERC20, etc)\n",
    "- TransactionHash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Centralized and Decentralized Exchanges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Decentralized Exchanges (DEX):</b>\n",
    "- is a contract stored onchain and executed by EVM (in a case of Ethereum)\n",
    "- to bet you need to send the transaction\n",
    "- every trade is stored in the blockchain\n",
    "- do not owe users' funds\n",
    "- 100% transparent\n",
    "- may have or may not have UI\n",
    "\n",
    "DEXes:\n",
    "- IDEX\n",
    "- Kyber\n",
    "- Oasis etc..\n",
    "\n",
    "\n",
    "*may not work with ETH but with WETH or KyberETH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ð¡entralized Exchanges (DEX):</b>\n",
    "- is a real-world entity\n",
    "- owe custodian addresses (hot/cold wallets)\n",
    "- trades happen on the exchange engine and are not stored in the blockchain\n",
    "- do owe users' funds\n",
    "- non transparent\n",
    "- intercation via UI\n",
    "\n",
    "CEXes:\n",
    "- [Binance](https://etherscan.io/address/0x3f5ce5fbfe3e9af3971dd833d26ba9b5c936f0be)\n",
    "- [Bitfinex](https://etherscan.io/address/0x876eabf441b2ee5b5b0554fd502a8e0600950cfa)\n",
    "- [Huobi](https://etherscan.io/address/0xd8a83b72377476d0a66683cde20a8aad0b628713)\n",
    "- [Coinbase](https://etherscan.io/address/0x89135c5ea509a1395287ddcdeb1ec307aed78c15) etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"exchanges.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Deposit and Withdrawal addresses</b>\n",
    "https://etherscan.io/address/0xc96d9e6361d344781eae1314b306cfbd73696606"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Sanpy](https://github.com/santiment/sanpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install sanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install fbprophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import san\n",
    "from san.backtest import Backtest\n",
    "from fbprophet import Prophet\n",
    "\n",
    "from utils import fancy_plot, get_san_metric\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keys import KEY_ as KEY\n",
    "san.ApiConfig.api_key = KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_date = '2017-01-01'\n",
    "to_date = '2019-11-01'\n",
    "asset = 'ethereum'\n",
    "interval = '1d'\n",
    "\n",
    "# create batch object\n",
    "batch = san.Batch()\n",
    "\n",
    "# create a request\n",
    "batch.get(\n",
    "    f'daily_active_addresses/{asset}',\n",
    "    from_date=from_date,\n",
    "    to_date=to_date,\n",
    "    interval=interval\n",
    ")\n",
    "batch.get(\n",
    "    f'daily_active_deposits/{asset}',\n",
    "    from_date=from_date,\n",
    "    to_date=to_date,\n",
    "    interval=interval\n",
    ")\n",
    "batch.get(\n",
    "    f'prices/{asset}',\n",
    "    from_date=from_date,\n",
    "    to_date=to_date,\n",
    "    interval=interval\n",
    ")\n",
    "\n",
    "# execute the request\n",
    "[daa, dad, price] = batch.execute()\n",
    "\n",
    "# merge dataframes\n",
    "data = daa.rename(columns={'value':'activeAddresses'}).join(dad).join(price['priceUsd'])\n",
    "\n",
    "# take a look\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical glimpse\n",
    "fancy_plot(data.rolling(3).mean(), ['activeAddresses', 'activeDeposits'], 'priceUsd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> Pumps on Centralized Exchanges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- no way to see what's inside CEX\n",
    "- but it's possible to observe the activity of CEX' wallets\n",
    "\n",
    "**Assumption:**\n",
    "There's an abnormal onchain activity before the pump.\n",
    "\n",
    "**Metric to observe**: exchange flow balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_date = '2018-06-01' # skip bullrun\n",
    "to_date = '2019-11-01'\n",
    "asset = 'santiment'\n",
    "\n",
    "ex_flow = get_san_metric(from_date, to_date, 'exchange_funds_flow', asset, interval='1d', iterate_over_days=700)\n",
    "price = get_san_metric(from_date, to_date, 'prices', asset, interval='1h', iterate_over_days=120)\n",
    "\n",
    "data = price.join(ex_flow).fillna(0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fancy_plot(data, ['priceUsd'], 'inOutDifference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> How to define abnormal activity? </b>\n",
    "- Statistical way (Granger test, Event study, etc)\n",
    "- Backtest it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create backtesting strategy you have to define 2 things:\n",
    "- when to BUY (1)\n",
    "- when to SELL (2)\n",
    "\n",
    "**1)** In order to specify **\"entry point\"**: create a signal on top of the metric (abnormal exchange flow => buy!)\n",
    "\n",
    "How to define an \"abnormal\" behaviour of the metric?\n",
    "- simple method (>= rolling mean value; outstanding values)\n",
    "- Facebook approach (actual value is outside the predicted confidence interval)\n",
    "- [Google approach](https://drive.google.com/file/d/1TyfMYV_hUmHbAKdY6iSnH_LqGkid3Srt/view)\n",
    "\n",
    "\n",
    "**2)** (tricky one) In order to specify **exit point**:\n",
    "- naive way (price thresholds)\n",
    "- signalling (create signals on top of other metrics)\n",
    "- ML approach (predict tops, haven't try it yet!)\n",
    "- your ideas? :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect anomalies: [Prophet](https://github.com/facebook/prophet/tree/master/python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"prophet.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_flow_train = get_san_metric(\n",
    "    start='2018-01-01',\n",
    "    end='2019-11-01',\n",
    "    metric='exchange_funds_flow',\n",
    "    asset='santiment',\n",
    "    interval='1d', \n",
    "    iterate_over_days=700\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data to prophet-readable format\n",
    "ex_flow_train = ex_flow_train.reset_index()\n",
    "ex_flow_train.columns = ['ds', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit the model\n",
    "model = Prophet(seasonality_mode='additive')\n",
    "\n",
    "model.fit(ex_flow_train[ex_flow_train['ds'] < ex_flow.index[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the next 30 days\n",
    "\n",
    "future = model.make_future_dataframe(periods=30)\n",
    "pred = model.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try different confidence intervals\n",
    "gap = (datetime.datetime.strptime(to_date, '%Y-%m-%d') - datetime.datetime.strptime(from_date, '%Y-%m-%d')).days\n",
    "predicted = pd.DataFrame(None)\n",
    "\n",
    "for month in range(gap // 30 + 1):\n",
    "    model = Prophet(seasonality_mode='additive', interval_width=0.25)\n",
    "    model.fit(ex_flow_train[ex_flow_train['ds'] < ex_flow.index[month * 30]])\n",
    "    future = model.make_future_dataframe(periods=30)\n",
    "    pred = model.predict(future.iloc[-30:])\n",
    "    predicted = predicted.append(\n",
    "        pred[['ds', 'yhat_lower', 'yhat_upper']]\n",
    "    )\n",
    "    \n",
    "predicted = predicted.rename(columns={'ds': 'datetime'}).set_index('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_predicted = data.join(predicted, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fancy_plot(data_predicted.ffill(), ['inOutDifference', 'yhat_lower', 'yhat_upper'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple backtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use **sanpy backtest** tool. \n",
    "\n",
    "Sanpy backtest is a super-simple backtest tool that aims to backtest a given strategy on a given asset's price. \n",
    "\n",
    "It takes vector of bools for every datepoint. \"True\" indicates buying or hodling asset on a given time interval and \"False\" stands for selling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly price returns \n",
    "data_predicted[\"returns\"] = data_predicted['priceUsd'].pct_change().fillna(0)\n",
    "# Created Strategy\n",
    "data_predicted['signal'] = (data_predicted['inOutDifference'] < data_predicted['yhat_lower']) | (data_predicted['inOutDifference'] > data_predicted['yhat_upper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fancy_plot(\n",
    "    data_predicted,\n",
    "    ['priceUsd'],\n",
    "    'inOutDifference',\n",
    "    signals=data_predicted[data_predicted['signal']==True].index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple strategy creation function. \n",
    "# The idea is to take signals generated from the metric and \n",
    "# create the \"hodling vector\" from it. \n",
    "# Relies on simple stop-loss strategy.\n",
    "\n",
    "def create_strategy(\n",
    "    df:pd.DataFrame,\n",
    "    price_name:str,\n",
    "    signal_name:str,\n",
    "    gain_to_exit:float,\n",
    "    loose_to_exit:float,\n",
    "    max_intervals_to_hodl=np.inf\n",
    "):\n",
    "\n",
    "    strategy = df[signal_name].copy()\n",
    "    state = {'price':None, 'hodl_days': None}\n",
    "\n",
    "    for t in range(len(strategy)):\n",
    "\n",
    "        if strategy[t] and not state['price']:  # if signal and asset is not already bought\n",
    "            # buy asset\n",
    "            state['price'] = df[price_name][t]\n",
    "            state['hodl_intervals'] = 0\n",
    "\n",
    "        elif state['price']:  # if asset is already bought\n",
    "            if df[price_name][t] > (1 + gain_to_exit) * state['price'] or \\\n",
    "               df[price_name][t] < (1 - loose_to_exit) * state['price'] or \\\n",
    "               state['hodl_intervals'] > max_intervals_to_hodl:  \n",
    "                # sell asset\n",
    "                state['price'], state['hodl_intervals'] = None, None\n",
    "                strategy[t] = False\n",
    "            else:\n",
    "                # keep hodling\n",
    "                strategy[t] = True\n",
    "                state['hodl_intervals'] += 1\n",
    "\n",
    "    return strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hodling the asset (benchmark) gives **-75.76%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A kind of grid-search for finding best params:\n",
    "\n",
    "Running the code takes ~10min so I've precomputed results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# price_name = 'priceUsd'\n",
    "# signals_name = 'signal'\n",
    "# backtest_results = []\n",
    "\n",
    "# for gain_to_exit in np.arange(0.01, 1.02, 0.05):\n",
    "#     for loose_to_exit in np.arange(0.01, 1.02, 0.05):\n",
    "        \n",
    "#         data_predicted['trades'] = create_strategy(data_predicted, price_name, signals_name, gain_to_exit, loose_to_exit)\n",
    "#         bt = Backtest(data_predicted.returns.dropna(), data_predicted.trades)\n",
    "\n",
    "#         backtest_results.append({\n",
    "#             'gain_to_exit': round(gain_to_exit, 3),\n",
    "#             'loose_to_exit': round(loose_to_exit, 3),\n",
    "#             'returns': bt.get_return(decimals=4)\n",
    "#         })\n",
    "\n",
    "# backtest_results = pd.DataFrame(backtest_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backtest_results.to_csv('backtest_results_prophet.csv', index=False)\n",
    "backtest_results = pd.read_csv('backtest_results_prophet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap of strategy outcomes:\n",
    "\n",
    "backtest_results_df = backtest_results[['gain_to_exit', 'loose_to_exit', 'returns']]\\\n",
    "    .set_index(['gain_to_exit', 'loose_to_exit'])\\\n",
    "    .unstack('loose_to_exit')\n",
    "backtest_results_df.columns = backtest_results_df.columns.droplevel()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14.0, 12.0)\n",
    "plt.pcolor(backtest_results_df, cmap=\"seismic\", edgecolors='k', linewidths=0.3)\n",
    "plt.yticks(np.arange(0.5, len(backtest_results_df.index), 1), backtest_results_df.index)\n",
    "plt.xticks(np.arange(0.5, len(backtest_results_df.columns), 1), backtest_results_df.columns, rotation='vertical')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's estimate average strategy results Vs benchmark (hodling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10,6))\n",
    "ax1.plot(\n",
    "    [round(i,2) for i in np.arange(0,1.01,0.05)],\n",
    "    [pd.DataFrame(backtest_results)['returns'].quantile(i) for i in np.arange(0,1.01,0.05)],\n",
    "    label='strategy perfomance dist'\n",
    ")\n",
    "ax1.hlines(bt.get_return_benchmark(), 0, 1, label='hodling')\n",
    "plt.grid()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect anomalies: naive way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create signals\n",
    "ex_flow_train['quantile90'] = ex_flow_train['y'].rolling(90, center=False).quantile(0.9)\n",
    "\n",
    "ex_flow_train['signal'] = ex_flow_train.apply(\n",
    "    lambda row: True if row['y'] >= row['quantile90'] and row['quantile90'] != np.nan else False,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "data_simplestr = data.join(ex_flow_train.set_index('ds')[['signal']], how='left')\n",
    "data_simplestr['signal'] = data_simplestr['signal'].fillna(False)\n",
    "data_simplestr[\"returns\"] = data_simplestr['priceUsd'].pct_change().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fancy_plot(\n",
    "    data_simplestr,\n",
    "    ['priceUsd'],\n",
    "    'inOutDifference',\n",
    "    signals=data_simplestr[data_simplestr['signal']==True].index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# price_name = 'priceUsd'\n",
    "# signals_name = 'signal'\n",
    "# backtest_results = []\n",
    "\n",
    "# for gain_to_exit in np.arange(0.01, 1.02, 0.05):\n",
    "#     for loose_to_exit in np.arange(0.01, 1.02, 0.05):\n",
    "        \n",
    "#         data_simplestr['trades'] = create_strategy(data_simplestr, price_name, signals_name, gain_to_exit, loose_to_exit)\n",
    "#         bt = Backtest(data_simplestr.returns.dropna(), data_simplestr.trades)\n",
    "\n",
    "#         backtest_results.append({\n",
    "#             'gain_to_exit': round(gain_to_exit, 3),\n",
    "#             'loose_to_exit': round(loose_to_exit, 3),\n",
    "#             'returns': bt.get_return(decimals=4)\n",
    "#         })\n",
    "\n",
    "# backtest_results = pd.DataFrame(backtest_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again use precomputed outcomes\n",
    "\n",
    "#backtest_results.to_csv('backtest_results_simplestr90.csv', index=False)\n",
    "backtest_results = pd.read_csv('backtest_results_simplestr90.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest_results_df = backtest_results[['gain_to_exit', 'loose_to_exit', 'returns']]\\\n",
    "    .set_index(['gain_to_exit', 'loose_to_exit'])\\\n",
    "    .unstack('loose_to_exit')\n",
    "backtest_results_df.columns = backtest_results_df.columns.droplevel()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14.0, 12.0)\n",
    "plt.pcolor(backtest_results_df, cmap=\"seismic\", edgecolors='k', linewidths=0.3)\n",
    "plt.yticks(np.arange(0.5, len(backtest_results_df.index), 1), backtest_results_df.index)\n",
    "plt.xticks(np.arange(0.5, len(backtest_results_df.columns), 1), backtest_results_df.columns, rotation='vertical')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10,6))\n",
    "ax1.plot(\n",
    "    [round(i,2) for i in np.arange(0,1.01,0.05)],\n",
    "    [pd.DataFrame(backtest_results)['returns'].quantile(i) for i in np.arange(0,1.01,0.05)],\n",
    "    label='strategy perfomance dist'\n",
    ")\n",
    "ax1.hlines(bt.get_return_benchmark(), 0, 1, label='hodling')\n",
    "plt.grid()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OHLC pricing data: use hourly highest prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section uses hourly highest price data as pricesource. The assumption is that you're able to\n",
    "spot exit points perfectly. To be more honest to other approaches lets also assume that the asset is bought \n",
    "in the worst moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "\n",
    "ohlc = get_san_metric(\n",
    "    start='2018-06-01',\n",
    "    end='2019-11-01',\n",
    "    metric='ohlc',\n",
    "    asset='santiment',\n",
    "    interval='1h', \n",
    "    iterate_over_days=120\n",
    ")\n",
    "\n",
    "high_price = ohlc[['highPriceUsd']]\n",
    "high_price.ix[high_price[high_price.highPriceUsd == 0].index, 'highPriceUsd'] = 0.187765  # Fix missing point\n",
    "high_price['returns'] = high_price['highPriceUsd'].pct_change().fillna(0)\n",
    "high_price = high_price.join(ex_flow_train.set_index('ds')[['y', 'signal']], how='left').fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# price_name = 'highPriceUsd'\n",
    "# signals_name = 'signal'\n",
    "# backtest_results = []\n",
    "\n",
    "# for gain_to_exit in np.arange(0.01, 1.02, 0.05):\n",
    "#     for loose_to_exit in np.arange(0.01, 1.02, 0.05):\n",
    "        \n",
    "#         high_price['trades'] = create_strategy(high_price, price_name, signals_name, gain_to_exit, loose_to_exit)\n",
    "#         bt = Backtest(high_price.returns.dropna(), high_price.trades)\n",
    "\n",
    "#         backtest_results.append({\n",
    "#             'gain_to_exit': round(gain_to_exit, 3),\n",
    "#             'loose_to_exit': round(loose_to_exit, 3),\n",
    "#             'returns': bt.get_return(decimals=4)\n",
    "#         })\n",
    "\n",
    "# backtest_results = pd.DataFrame(backtest_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again use precomputed outcomes\n",
    "\n",
    "#backtest_results.to_csv('backtest_results_high_price_simplestr.csv', index=False)\n",
    "backtest_results = pd.read_csv('backtest_results_high_price_simplestr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest_results_df = backtest_results[['gain_to_exit', 'loose_to_exit', 'returns']]\\\n",
    "    .set_index(['gain_to_exit', 'loose_to_exit'])\\\n",
    "    .unstack('loose_to_exit')\n",
    "backtest_results_df.columns = backtest_results_df.columns.droplevel()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14.0, 12.0)\n",
    "plt.pcolor(backtest_results_df, cmap=\"seismic\", edgecolors='k', linewidths=0.3)\n",
    "plt.yticks(np.arange(0.5, len(backtest_results_df.index), 1), backtest_results_df.index)\n",
    "plt.xticks(np.arange(0.5, len(backtest_results_df.columns), 1), backtest_results_df.columns, rotation='vertical')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall results\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10,6))\n",
    "ax1.plot(\n",
    "    [round(i,2) for i in np.arange(0,1.01,0.05)],\n",
    "    [pd.DataFrame(backtest_results)['returns'].quantile(i) for i in np.arange(0,1.01,0.05)],\n",
    "    label='strategy perfomance dist'\n",
    ")\n",
    "ax1.hlines(bt.get_return_benchmark(), 0, 1, label='hodling')\n",
    "plt.grid()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_simplestr['trades'] = create_strategy(data_simplestr, 'priceUsd', 'signal', 0.81, 0.01)\n",
    "\n",
    "# bt = Backtest(data_simplestr.returns.dropna(), data_simplestr.trades)\n",
    "# bt.summary()\n",
    "# bt.plot_backtest(viz='hodl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play yourself :)\n",
    "\n",
    "# df: high_price  # Strategy with hourly high price and naive signals detection\n",
    "# df: data_simplestr  # Strategy with hourly average price and naive signals detection\n",
    "# df: data_predicted  # Strategy with hourly average price and predicted by prophet anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> TLDR and open questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Its possible to foresee upcoming pumps using centralized exchanges activity\n",
    "\n",
    "- Naive way of detecting anomalies works better than prophet predicted anomalies (TODO: experiment with confidence intervals).\n",
    "\n",
    "- It's important not only to foresee pumps but only to find right \"exit\" moment. (TODO: experiment with finding tops using other metrics (like soical volume, active addresses, etc)).\n",
    "\n",
    "- Than more exchange addresses is in the sample the better strategies work. (DISCUSSION: identifying CEX wallets onchain). \n",
    "\n",
    "- DISCUSSION: with deposit addresses it's possible to tract different wallets of the user. Any connections between pump-makers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions? Ideas? \n",
    "Find me here:\n",
    "alex.g@santiment.net \n",
    "(WhatsApp, Telegram): +375256830154\n",
    "or join us on **santiment.net** or [our discord channel](https://discord.gg/q3m9vUg)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
